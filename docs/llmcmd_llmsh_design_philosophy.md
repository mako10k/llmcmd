# llmcmd / llmsh 設計思想ドキュメント

最終更新: 2025-08-14  
対象: プロジェクト新規/継続開発者, アーキテクト, レビュー担当  

---
## 1. 目的と位置付け
`llmcmd` と `llmsh` は「LLM が安全な“閉じた計算環境”内で、ファイル加工・テキスト整形・自己再帰的分解を行いながら高品質出力を生成する」ための二形態インターフェースである。

| コンポーネント | 主用途 | モード | 代表特徴 |
|---------------|--------|--------|-----------|
| llmcmd | 1ショット / バッチ指向の LLM 指示実行 | コマンドラインツール | OpenAI API 直結 / プロンプト + 入出力束ね / プリセット / 再帰実行サポート |
| llmsh  | ミニマル“LLM向け”シェル / スクリプト合成 | 対話 / パイプライン | 安全な内部ビルトインのみ / 外部コマンド不許可 / VFS + Quota 継承 / LLM 主体の分割統治 |

両者は **共通 VFS / Quota / ツール実行エンジン** を共有し、利用者（あるいは上位オーケストレータ LLM）が状況に応じて「一発指示 (llmcmd)」と「段階的構築 (llmsh)」を切り替えられる統一モデルを志向する。

---
## 2. 共通コア哲学
1. **Security First**: 外部任意コマンドや環境汚染要素を排除し、ビルトイン関数 + 制限付き VFS のみで操作。  
2. **Fail-First**: 条件違反・設定異常・安全境界逸脱を即時検知・終了。エラーは “静かに無視” しない。  
3. **Simplicity → Composability**: 機能粒度を小さく (cat, grep, sed, wc 等) 保ち LLM によるパイプライン合成余地を最大化。  
4. **Deterministic & Auditable**: I/O, quota, API 呼び出し数を明示管理し再現性確保。  
5. **Extensibility**: ツール追加や VFS / fsproxy 統合を段階展開できる層状アーキテクチャ。  
6. **Cost Awareness**: Weighted token (Input:1 / Cached:0.25 / Output:4) に基づくリアルタイム残量監視。  
7. **Unified Abstractions**: llmcmd ↔ llmsh が同一プリミティブ上で動作し、差異は UX と使用文脈のみ。  

---
## 3. アーキテクチャ層 (概略)
```
User / Orchestrator LLM
        │
  (CLI / Shell Front)  ← llmcmd / llmsh
        │
   Application Layer (app, cli)
        │
   Tool Execution Engine (tools + builtin commands)
        │
   OpenAI Client (retry / quota / auth)
        │
   VFS / FS Proxy (仮想化 + サイズ/権限ガード)
        │
   Host Filesystem (制限付き)
```
- **共通ツール群**: read / write / spawn(制限) / exit + テキスト系ビルトイン。  
- **VFS**: 抽象化されたファイルアクセス制御面。fsproxy プロトコル統合計画により llmsh / llmcmd が統一 API 経由で安全操作。  
- **Quota Manager**: API 呼び出し回数・トークン消費を集約。サブシェル / 再帰で継承。  
- **Preset Prompt System**: 安全な標準化指示テンプレートで再現性・品質平準化。  

---
## 4. llmcmd の設計思想
| 観点 | 方針 | 背景 / 意図 |
|------|------|-------------|
| コア機能 | 単発・明示的指示を OpenAI API に送り、ファイル/標準入出力を束ね | スクリプト / CI / バッチ適性 |
| 再帰呼び出し | llmcmd 自身をプロンプト生成チェーン内で再入可能 | 複雑タスクの段階分解 (Two-Stage / Multi-Step) |
| Two-Stage モード | 計画 (大モデル) → 実行 (軽量モデル) | コスト最適化 + 高品質計画 |
| 構成管理 | CLI Flags + 環境変数 + rc (優先順位付き) | DevOps / CI パイプライン統合容易化 |
| Quota Enforcement | 超過即失敗 (Fail-First) | コスト暴走防止 / 透明性 |
| VFS 利用 | 入力集約 / 出力整形 / 生成成果物再利用 | 一貫した I/O モデル |
| エラー指針 | 実行前検証 (config, size, timeout) 即終了 | 後続副作用抑止 |
| プリセット | 標準化プロンプト (diff/patch 等) | 再現性と安全なツール誘導 |

### llmcmd が重視する非機能要求
- 冪等性 (入力と設定が同一なら同じ振る舞い)  
- 監査容易性 (ログ + 統計)  
- スクリプタビリティ (単一プロセス/戻りコード明確)  

---
## 5. llmsh の設計思想
| 観点 | 方針 | 補足 |
|------|------|------|
| ミニマルシェル | POSIX 完全互換を追わず “LLM に最小限必要” な構文 | 過剰機能は攻撃面拡大リスク |
| ビルトイン限定 | 外部プロセス禁止 (再帰 llmcmd など許可例外最小化) | サンドボックス堅牢化 |
| パイプライン指向 | cat | grep | sed | llmcmd の連結容易 | LLM による逐次精緻化を想定 |
| Quota 継承 | 親 llmcmd / 上位 llmsh から残量伝搬 | コスト境界の明示保持 |
| Virtual FS | fsproxy 統合後は仮想 FD テーブルで追跡 | ファイル逸脱抑止 / 容量課金制御 |
| エラー即露出 | 曖昧な黙殺 (書き込み失敗など) を避ける共通ハンドラ | 以前の“静かな失敗”撲滅施策 |
| スクリプト化 | LLM がシェルスクリプトを内部生成し実行 | “計画→操作” 反復効率向上 |

### llmsh の価値提供
- LLM 自身が「観察 → 変換 → 再評価」サイクルを内部で短いビルトイン連鎖に還元。  
- 外部 OS コマンドに依存しないためプラットフォーム差異縮小 / セキュリティ明瞭化。  

---
## 6. 両者の補完関係
| シナリオ | 推奨 | 理由 |
|----------|------|------|
| 単純処理 + 明確指示 | llmcmd | 起動オーバーヘッド最小 / 単発終了 |
| 複合ログ解析 / 段階抽出 | llmsh + 部分で llmcmd | インクリメンタル検査 + 要約 |
| 大型テキスト分割後集約 | llmsh (分割) → llmcmd (要約統合) | トークン利用最適化 |
| プロンプト品質テンプレ適用 | llmcmd (preset) → llmsh 生成結果検証 | 標準化 + 柔軟編集 |

---
## 7. セキュリティ & サンドボックス戦略
| 項目 | ポリシー |
|------|----------|
| 外部コマンド実行 | 原則禁止 (spawn は内部/制限的) |
| ファイルサイズ | 10MB 上限 (CONFIG / rc で検証) |
| 読取バッファ | 4KB ストリーミング + メモリ使用抑制 |
| API 呼び出し | セッション上限 50 (デフォルト) |
| Quota 重量付 | Input 1.0 / Cached 0.25 / Output 4.0 |
| 失敗時動作 | 即時終了 (log.Fatal / error 伝播) |

fsproxy / VFS 統合は「(a) 仮想 FD 管理」「(b) プロトコルレベル許可制」「(c) 監査可能イベントログ」によって最小権限実現を拡張予定。 

---
## 8. エラーモデルと Fail-First 運用
| 分類 | 例 | 振る舞い |
|------|----|----------|
| 設定異常 | 無効 JSON / 不正数値 | 直ちに終了 (再実行で再現) |
| ユーザ入力 | 予期しないフラグ | 明確メッセージ + 非 0 終了 |
| I/O 境界 | サイズ超過 / 書込失敗 | 直ちに終了 (部分結果無効化) |
| LLM API | 認証 / レート / 一時障害 | 限定リトライ → 失敗確定 |
| 内部前提崩壊 | 不変条件違反 | panic / fatal (バグ修正対象) |

改善履歴例: `HandleHelp` が書き込みエラー黙殺 → エラー伝播へ変更 (2025-08)。

---
## 9. コスト & Quota フィロソフィ
- **可視性**: 実行中に残量を逐次表示 (将来: TUI / JSON Stats)  
- **防波堤**: 想定外増幅 (再帰 / 無限分割) を上限カウンタで遮断。  
- **軽量試行優先**: 失敗しやすい初期探索は低トークン (mini モデル) / 決定フェーズのみ高品質モデル。  

---
## 10. 進化ロードマップ (高レベル)
| フェーズ | 概要 | 価値 |
|----------|------|------|
| v3.x 現状 | 統合ヘルプ / Quota / ビルトイン安定化 | 信頼性基盤 |
| fsproxy 完全統合 | llmsh へ安全 FD 経路 / 監査ログ | セキュリティ強化 |
| Unified VFS Server | 両コンポーネント同一抽象で集中管理 | 重複除去 & 一貫性 |
| Two-Stage 実行 | 複雑計画→実行分離 | コスト最適化 + 精度 |
| 高度プリセット/テンプレ | 規範プロンプト自動選択 | 品質 & 組織知共通化 |
| 静的解析 / Lint 強化 | サイレント失敗パターン検出 | 品質自動防衛 |

---
## 11. トレードオフ / 非ゴール
| 項目 | 非ゴール宣言 | 理由 |
|------|---------------|------|
| POSIX 互換完全性 | 目指さない | 守備範囲拡張は攻撃面と複雑性増大 |
| 任意外部コマンド | 追加予定なし | セキュリティモデル崩壊 |
| 巨大バイナリ処理 | 優先外 | LLM 主体ユースケースはテキスト偏重 |
| モデル切替の完全自動推論 | 長期視野 | 初期は明示フラグで制御し透明性維持 |

---
## 12. 代表的デザイン判断例 (Decision Log 抜粋)
| テーマ | 判断 | 根拠/影響 |
|--------|------|-----------|
| Help 出力統合 | `HandleHelp` 共通化 | 20 コマンドの重複排除 / 改修集約 |
| Help 書込失敗処理 | エラー伝播へ変更 | Fail-First 徹底 / サイレント抑止 |
| Dry-Run (patch) | 検証失敗でも exit 0 (現状) | UX 優先 (後で strict モード検討) |
| Quota 重量付 | Output 係数 4.0 | 出力生成コスト高リスク抑制 |
| 外部コマンド禁止 | 内部ビルトインのみ | 攻撃面縮小 + 再現性 |

---
## 13. 今後の改善アイデア (Backlog 候補)
- `patch --strict-dry-run` で検証失敗を非 0 戻り値化。  
- file.Close() エラー透過ラップユーティリティ導入。  
- サイレントパターン検出テスト (unused write / ignored error) 自動化。  
- プリセット選択ヒューリスティクス (ドメイン分類 → テンプレ選択)。  
- Quota 可視化 JSON API エンドポイント / メトリクス出力。  
- LLM 行動メトリクス (retry 分布 / 温度差異) 収集分析。  

---
## 14. まとめ
llmcmd / llmsh は「LLM が安全・一貫・監査可能な形で自己拡張的処理を行う」ための二形態 UI であり、設計核心は以下に凝縮される:
- 小さく信頼できるビルトインプリミティブ
- Fail-First + 明示的 Quota によるコスト境界
- 再帰/段階的実行とパイプライン合成で複雑度制御
- 共有 VFS / fsproxy で統一 I/O セマンティクス
- セキュリティと拡張性のバランスを意図的に最適化

このドキュメントは新規コントリビュータが「どの価値基準で判断すべきか」を最短で把握するためのコンパスである。継続改善時は決定の根拠を本書に追記し知識の腐敗を防ぐこと。
